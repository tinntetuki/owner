# 实时计算与流处理深度解析

## 目录
- [一、Flink实战](#一flink实战)
- [二、实时数据管道](#二实时数据管道)
- [三、Lambda与Kappa架构](#三lambda与kappa架构)
- [四、高频面试题](#四高频面试题)

## 一、Flink实战

### 1.1 State管理

```java
public class CountWindowAverage 
        extends RichFlatMapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>> {
    
    private transient ValueState<Tuple2<Long, Long>> sum;
    
    @Override
    public void open(Configuration parameters) {
        ValueStateDescriptor<Tuple2<Long, Long>> descriptor = 
            new ValueStateDescriptor<>("average", 
                TypeInformation.of(new TypeHint<Tuple2<Long, Long>>() {}));
        sum = getRuntimeContext().getState(descriptor);
    }
    
    @Override
    public void flatMap(Tuple2<Long, Long> input, 
                       Collector<Tuple2<Long, Long>> out) throws Exception {
        Tuple2<Long, Long> currentSum = sum.value();
        
        if (currentSum == null) {
            currentSum = Tuple2.of(0L, 0L);
        }
        
        currentSum.f0 += 1;
        currentSum.f1 += input.f1;
        sum.update(currentSum);
        
        if (currentSum.f0 >= 2) {
            out.collect(Tuple2.of(input.f0, currentSum.f1 / currentSum.f0));
            sum.clear();
        }
    }
}
```

### 1.2 Watermark

```java
WatermarkStrategy<Event> watermarkStrategy = WatermarkStrategy
    .<Event>forBoundedOutOfOrderness(Duration.ofSeconds(5))
    .withTimestampAssigner((event, timestamp) -> event.getTimestamp());

DataStream<Event> stream = env
    .fromSource(source, watermarkStrategy, "Kafka Source")
    .keyBy(Event::getUserId)
    .window(TumblingEventTimeWindows.of(Time.minutes(1)))
    .process(new MyProcessWindowFunction());
```

### 1.3 Checkpoint

```java
env.enableCheckpointing(60000);  // 60秒checkpoint一次
env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
env.getCheckpointConfig().setMinPauseBetweenCheckpoints(500);
env.getCheckpointConfig().setCheckpointTimeout(60000);
env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);
```

## 二、实时数据管道

### 2.1 架构

```
数据源（Kafka）
    ↓
数据清洗（Flink）
    ↓
数据存储（HBase/ClickHouse）
    ↓
数据展示（Grafana/Kibana）
```

### 2.2 实时ETL

```java
@FunctionHint(output = @DataTypeHint("ROW<user_id BIGINT, pv BIGINT, uv BIGINT>"))
public class UserBehaviorAggregateFunction extends AggregateFunction<
        Tuple3<Long, Long, Long>,  // ACC
        Tuple3<Long, Long, Long>   // OUT
        > {
    
    @Override
    public Tuple3<Long, Long, Long> createAccumulator() {
        return Tuple3.of(0L, 0L, 0L);
    }
    
    @Override
    public Tuple3<Long, Long, Long> add(UserBehavior value, 
                                        Tuple3<Long, Long, Long> acc) {
        return Tuple3.of(
            value.getUserId(),
            acc.f1 + 1,  // pv
            acc.f2 + (acc.f2 == 0 ? 1 : 0)  // uv
        );
    }
    
    @Override
    public Tuple3<Long, Long, Long> getResult(Tuple3<Long, Long, Long> acc) {
        return acc;
    }
    
    @Override
    public Tuple3<Long, Long, Long> merge(Tuple3<Long, Long, Long> a, 
                                          Tuple3<Long, Long, Long> b) {
        return Tuple3.of(a.f0, a.f1 + b.f1, a.f2 + b.f2);
    }
}
```

## 三、Lambda与Kappa架构

### 3.1 Lambda架构

```
数据源
 ├─→ 批处理层（Spark）→ 批处理视图 ─┐
 │                                 ├─→ 服务层 → 查询
 └─→ 实时处理层（Flink）→ 实时视图 ─┘
```

**特点**：
- 批处理保证准确性
- 实时处理保证低延迟
- 需要维护两套代码

### 3.2 Kappa架构

```
数据源 → 流处理（Flink）→ 存储 → 查询
```

**特点**：
- 只有流处理
- 代码简洁
- 依赖重放能力

## 四、高频面试题

### Q1：Flink如何保证Exactly-Once？

1. **Source**：可重放（Kafka offset）
2. **Process**：Checkpoint + State
3. **Sink**：两阶段提交（2PC）

### Q2：Watermark的作用？

- 处理乱序数据
- 触发窗口计算
- 允许一定延迟

### Q3：Flink的背压机制？

- 下游处理慢时，反向传播
- 限制上游发送速率
- 保护系统稳定性

---

**关键字**：Flink、实时计算、Watermark、Checkpoint、Lambda、Kappa

